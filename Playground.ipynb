{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T15:35:30.752359429Z",
     "start_time": "2023-07-31T15:35:30.554538765Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "from scipy.io import savemat, loadmat\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T15:35:32.326609358Z",
     "start_time": "2023-07-31T15:35:30.570361203Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = './ckpt/combined_model.onnx'\n",
    "\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "input_names = [input.name for input in onnx_model.graph.input]\n",
    "output_names = [output.name for output in onnx_model.graph.output]\n",
    "print(f'Model inputs: {input_names}')\n",
    "print(f'Model output: {output_names}')\n",
    "\n",
    "del onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T15:35:32.326895092Z",
     "start_time": "2023-07-31T15:35:32.315203458Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_results(\n",
    "        results_dir,\n",
    "        sample_idx,\n",
    "        image,\n",
    "        gt_edges,\n",
    "        gt_corners,\n",
    "        pred_edges,\n",
    "        pred_corners,\n",
    "        room_type\n",
    "):\n",
    "    image = Image.fromarray((image * 255).astype(np.uint8).transpose(1, 2, 0))\n",
    "    \n",
    "    gt_edges_image = Image.fromarray((gt_edges * 255).astype(np.uint8).transpose(1, 2, 0))\n",
    "    gt_corners_image = Image.fromarray(\n",
    "        (gt_corners.sum(axis=0) * 255).astype(np.uint8))\n",
    "    \n",
    "    pred_edges_image = Image.fromarray((pred_edges * 255).astype(np.uint8).transpose(1, 2, 0))\n",
    "    pred_corners_image = Image.fromarray(\n",
    "        (pred_corners.sum(axis=0) * 255).astype(np.uint8))\n",
    "    \n",
    "    base_file = os.path.join(results_dir, f'{sample_idx}')\n",
    "    image.save(f'{base_file}_rt-{room_type}.jpg')\n",
    "    gt_edges_image.save(f'{base_file}_gt_edges.jpg')\n",
    "    gt_corners_image.save(f'{base_file}_gt_corners.jpg')\n",
    "    pred_edges_image.save(f'{base_file}_pred_edges.jpg')\n",
    "    pred_corners_image.save(f'{base_file}_pred_corners.jpg')\n",
    "\n",
    "    np.save(f'{base_file}_pred_corners.npy', pred_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T15:35:32.327019041Z",
     "start_time": "2023-07-31T15:35:32.315389916Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_results_mat(\n",
    "    results_dir,\n",
    "    sample_idx,\n",
    "    image,\n",
    "    pred_edges,\n",
    "    pred_corners,\n",
    "    pred_types\n",
    "):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on test set and save results in the same format as original Lua Torch LayoutNet project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T15:56:48.273129354Z",
     "start_time": "2023-07-31T15:56:45.216060013Z"
    }
   },
   "outputs": [],
   "source": [
    "REINFER = False\n",
    "\n",
    "src_images_dir = '/home/richard/Development/LayoutNet/data/lsun_val/img'\n",
    "results_dir = 'res/lsun_val'\n",
    "model_path = './ckpt/combined_model.onnx'\n",
    "\n",
    "ort_sess = ort.InferenceSession(model_path)\n",
    "\n",
    "cor_dir = os.path.join(results_dir, 'cor')\n",
    "cor_mat_dir = os.path.join(results_dir, 'cor_mat')\n",
    "cor_mat_flip_dir = os.path.join(results_dir, 'cor_mat_flip')\n",
    "edg_dir = os.path.join(results_dir, 'edg')\n",
    "img_dir = os.path.join(results_dir, 'img')\n",
    "type_dir = os.path.join(results_dir, 'type')\n",
    "type_gt_dir = os.path.join(results_dir, 'type_gt')\n",
    "\n",
    "for p in [cor_dir, cor_mat_dir, cor_mat_flip_dir, edg_dir, img_dir, type_dir]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def is_image(fname):\n",
    "    ext = fname.split('.')[-1]\n",
    "    return ext in {'jpg', 'jpeg', 'png'}\n",
    "\n",
    "src_images = sorted(filter(is_image, os.listdir(src_images_dir)))\n",
    "\n",
    "if REINFER:\n",
    "\n",
    "    for idx, image_file_name in tqdm(enumerate(src_images), total=len(src_images)):   \n",
    "        image_name = image_file_name.split('.')[0]\n",
    "        \n",
    "        image = Image.open(os.path.join(src_images_dir, image_file_name))\n",
    "        image = image.resize((512, 512))\n",
    "        image = np.array(image)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        image_flip = np.fliplr(image).copy()\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image_flip = image_flip.transpose(2, 0, 1)\n",
    "\n",
    "        x = np.expand_dims(image, axis=0)\n",
    "        x_flip = np.expand_dims(image_flip, axis=0)\n",
    "        \n",
    "        outputs = ort_sess.run(\n",
    "            None,\n",
    "            {\n",
    "                'input': x\n",
    "            }\n",
    "        )\n",
    "        outputs_flip = ort_sess.run(\n",
    "            None,\n",
    "            {\n",
    "                'input': x_flip\n",
    "            }\n",
    "        )\n",
    "\n",
    "        edges_out, corners_out, room_type_out = outputs\n",
    "        edges_out_flip, corners_out_flip, room_type_out_flip = outputs_flip\n",
    "\n",
    "        room_type_arr = np.stack([room_type_out[0], room_type_out_flip[0]], axis=0)\n",
    "        room_type_mat = {\n",
    "            'x': room_type_arr\n",
    "        }\n",
    "\n",
    "        edges_out_unflip =  np.fliplr(edges_out_flip[0].transpose(1, 2, 0)).transpose(2, 0, 1)\n",
    "        edges_arr = np.stack([edges_out[0], edges_out_unflip]).mean(axis=0)\n",
    "        edges_img = (edges_arr.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "        edges_img = Image.fromarray(edges_img)\n",
    "\n",
    "        cor_mat = {\n",
    "            'x': corners_out[0]\n",
    "        }\n",
    "        cor_mat_flip = {\n",
    "            'x': corners_out_flip[0]\n",
    "        }\n",
    "\n",
    "        cor_unflipped_sum = np.fliplr(corners_out_flip[0].sum(axis=0)).clip(0, 1)\n",
    "        cor_sum = corners_out[0].sum(axis=0).clip(0, 1)\n",
    "\n",
    "        cor_img = np.stack([\n",
    "            cor_unflipped_sum,  \n",
    "            cor_sum\n",
    "        ]).mean(axis=0)\n",
    "        cor_img = (cor_img * 255).astype(np.uint8)\n",
    "        # Our images dont actually look like in Torch7 inference, they are flipped over there.\n",
    "        cor_img = Image.fromarray(cor_img)\n",
    "\n",
    "        img = (image.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        base_file_name = str(idx + 1)\n",
    "        # TODO: create room_type_gt_mat in the same form as room_type_mat from the single 'id' value\n",
    "        savemat(os.path.join(type_dir, f'{base_file_name}.mat'), room_type_mat)\n",
    "        edges_img.save(os.path.join(edg_dir, f'{base_file_name}.png'))\n",
    "        savemat(os.path.join(cor_mat_dir, f'{base_file_name}.mat'), cor_mat)\n",
    "        savemat(os.path.join(cor_mat_flip_dir, f'{base_file_name}.mat'), cor_mat_flip)\n",
    "        cor_img.save(os.path.join(cor_dir, f'{base_file_name}.png'))\n",
    "        img.save(os.path.join(img_dir, f'{base_file_name}.png')) \n",
    "\n",
    "del ort_sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Reformat Ground Truth Data into Prediction Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T16:13:31.433219347Z",
     "start_time": "2023-07-31T16:13:31.252825918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_gt_dir = '/home/richard/Development/LayoutNet/data/lsun_val'\n",
    "src_gt_img_dir = os.path.join(src_gt_dir, 'img')\n",
    "src_gt_cor_dir = os.path.join(src_gt_dir, 'cor')\n",
    "src_gt_cor_flip_dir = os.path.join(src_gt_dir, 'cor_flip')\n",
    "src_gt_edg_dir = os.path.join(src_gt_dir, 'edg')\n",
    "src_gt_type_dir = os.path.join(src_gt_dir, 'type')\n",
    "\n",
    "dst_gt_dir = './res/lsun_val_gt'\n",
    "dst_gt_img_dir = os.path.join(dst_gt_dir, 'img')\n",
    "dst_gt_cor_dir = os.path.join(dst_gt_dir, 'cor')\n",
    "dst_gt_cor_mat_dir = os.path.join(dst_gt_dir, 'cor_mat')\n",
    "dst_gt_cor_mat_flip_dir = os.path.join(dst_gt_dir, 'cor_mat_flip')\n",
    "dst_gt_edg_dir = os.path.join(dst_gt_dir, 'edg')\n",
    "dst_gt_type_dir = os.path.join(dst_gt_dir, 'type')\n",
    "\n",
    "for dir in [dst_gt_img_dir, dst_gt_cor_dir, dst_gt_cor_mat_dir, dst_gt_cor_mat_flip_dir, dst_gt_edg_dir, dst_gt_type_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T16:13:32.634033836Z",
     "start_time": "2023-07-31T16:13:32.617512284Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_image_file_names = list(sorted(filter(is_image, os.listdir(src_gt_img_dir))))\n",
    "gt_image_file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T16:31:19.311041639Z",
     "start_time": "2023-07-31T16:15:29.478252111Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REFORMAT = False\n",
    "\n",
    "if REFORMAT:\n",
    "    for idx, gt_image_file_name in tqdm(enumerate(gt_image_file_names), total=len(gt_image_file_names)):\n",
    "        gt_sample_name = gt_image_file_name.replace('.png', '')\n",
    "        gt_mat_name = f'{gt_sample_name}.mat'\n",
    "        \n",
    "        gt_img = Image.open(os.path.join(src_gt_img_dir, gt_image_file_name))\n",
    "        gt_edg = Image.open(os.path.join(src_gt_edg_dir, gt_image_file_name))\n",
    "        gt_cor = loadmat(os.path.join(src_gt_cor_dir, gt_mat_name))['cor']\n",
    "        gt_cor_flip = loadmat(os.path.join(src_gt_cor_flip_dir, gt_mat_name))['cor_f']\n",
    "        gt_type_id = loadmat(os.path.join(src_gt_type_dir, gt_mat_name))['id']\n",
    "        \n",
    "        # Transform\n",
    "        gt_type_id = int(gt_type_id.squeeze())\n",
    "        gt_type = np.zeros((2, 11))\n",
    "        gt_type[:, gt_type_id - 1] = 1\n",
    "        \n",
    "        # HWC -> CHW\n",
    "        gt_cor = np.transpose(gt_cor, (2, 0, 1))\n",
    "        gt_cor_flip = np.transpose(gt_cor_flip, (2, 0, 1))\n",
    "        \n",
    "        gt_cor_unflipped_sum = np.fliplr(gt_cor.sum(axis=0)).clip(0, 1)\n",
    "        gt_cor_sum = gt_cor.sum(axis=0).clip(0, 1)\n",
    "\n",
    "        gt_cor_img = np.stack([\n",
    "            gt_cor_unflipped_sum,  \n",
    "            gt_cor_sum\n",
    "        ]).mean(axis=0)\n",
    "        gt_cor_img = (gt_cor_img * 255).astype(np.uint8)\n",
    "        gt_cor_img = Image.fromarray(gt_cor_img)\n",
    "        \n",
    "        # TODO: create mats\n",
    "        gt_room_type_mat = {\n",
    "            'x': gt_type\n",
    "        }\n",
    "        gt_cor_mat = {\n",
    "            'x': gt_cor\n",
    "        }\n",
    "        gt_cor_mat_flip = {\n",
    "            'x': gt_cor_flip\n",
    "        }\n",
    "        \n",
    "        base_file_name = str(idx + 1)\n",
    "        # TODO: create room_type_gt_mat in the same form as room_type_mat from the single 'id' value\n",
    "        savemat(os.path.join(dst_gt_type_dir, f'{base_file_name}.mat'), gt_room_type_mat)\n",
    "        gt_edg.save(os.path.join(dst_gt_edg_dir, f'{base_file_name}.png'))\n",
    "        savemat(os.path.join(dst_gt_cor_mat_dir, f'{base_file_name}.mat'), gt_cor_mat)\n",
    "        savemat(os.path.join(dst_gt_cor_mat_flip_dir, f'{base_file_name}.mat'), gt_cor_mat_flip)\n",
    "        gt_cor_img.save(os.path.join(dst_gt_cor_dir, f'{base_file_name}.png'))\n",
    "        gt_img.save(os.path.join(dst_gt_img_dir, f'{base_file_name}.png'))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compare Predictions with Ground-Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir = './res/lsun_val_gt'\n",
    "pred_dir = './res/lsun_val'\n",
    "\n",
    "pred_type_dir = os.path.join(pred_dir, 'type')\n",
    "gt_type_dir = os.path.join(gt_dir, 'type')\n",
    "\n",
    "num_samples = len(os.listdir(pred_type_dir))\n",
    "print(f'Number of samples: {num_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_to_wrong_preds = {}\n",
    "\n",
    "num_correct = 0\n",
    "for idx in range(1, num_samples + 1):\n",
    "    mat_file_name = f'{idx}.mat'\n",
    "\n",
    "    gt_type = loadmat(os.path.join(gt_type_dir, mat_file_name))['x'].mean(axis=0).argmax()\n",
    "    pred_type = loadmat(os.path.join(pred_type_dir, mat_file_name))['x'].mean(axis=0).argmax()\n",
    "    if gt_type != pred_type:\n",
    "        if gt_type not in gt_to_wrong_preds:\n",
    "            gt_to_wrong_preds[gt_type] = []\n",
    "        gt_to_wrong_preds[gt_type].append((idx, pred_type))\n",
    "    else:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Number of correct type predictions: {num_correct}')\n",
    "print(list(sorted(gt_to_wrong_preds.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_type, wrong_entries in sorted(gt_to_wrong_preds.items()):\n",
    "    print(f'{gt_type}: {len(wrong_entries)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_to_wrong_preds[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
