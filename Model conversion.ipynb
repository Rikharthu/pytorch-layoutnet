{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:22:41.707048Z",
     "start_time": "2023-07-23T10:22:41.657827Z"
    }
   },
   "outputs": [],
   "source": [
    "from model_wrapper import CombinedLayoutNetPersp\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:35.138686Z",
     "start_time": "2023-07-23T10:20:34.656574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder weights\n",
      "Loading edge decoder weights\n",
      "Loading corner decoder weights\n",
      "Loading type decoder weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CombinedLayoutNetPersp(\n",
       "  (encoder): Encoder(\n",
       "    (convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (edge_decoder): Decoder(\n",
       "    (convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (last_conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (corner_decoder): Decoder(\n",
       "    (convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(3072, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (last_conv): Conv2d(96, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (type_decoder): TypeDecoder(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Linear(in_features=32768, out_features=1024, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=64, out_features=11, bias=True)\n",
       "      (7): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model = CombinedLayoutNetPersp()\n",
    "combined_model.load_component_weights(\n",
    "    encoder_checkpoint_path='./ckpt/pre_encoder.pth',\n",
    "    edge_decoder_checkpoint_path='./ckpt/pre_edg_decoder.pth',\n",
    "    corner_decoder_checkpoint_path='./ckpt/pre_cor_decoder.pth',\n",
    "    type_decoder_checkpoint_path='./ckpt/pre_type_decoder.pth',\n",
    ")\n",
    "combined_model = combined_model.eval()\n",
    "combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:35.143976Z",
     "start_time": "2023-07-23T10:20:35.139505Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, ckpt_path):\n",
    "    trainer = pl.Trainer(accelerator='cpu')\n",
    "    trainer.strategy.connect(model)\n",
    "    trainer.save_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:35.744799Z",
     "start_time": "2023-07-23T10:20:35.143307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "save_model_checkpoint(combined_model, './ckpt/combined_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:36.244997Z",
     "start_time": "2023-07-23T10:20:35.745679Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_model = CombinedLayoutNetPersp.load_from_checkpoint('./ckpt/combined_model.ckpt')\n",
    "combined_model = combined_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.273832Z",
     "start_time": "2023-07-23T10:20:36.244814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, 3, 512, 512, strides=[786432, 262144, 512, 1], requires_grad=0, device=cpu),\n",
      "      %encoder.convs.0.0.0.weight : Float(32, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.0.0.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.1.0.0.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.1.0.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.2.0.0.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.2.0.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.3.0.0.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.3.0.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.4.0.0.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.4.0.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.5.0.0.weight : Float(1024, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.5.0.0.bias : Float(1024, strides=[1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.6.0.0.weight : Float(2048, 1024, 3, 3, strides=[9216, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %encoder.convs.6.0.0.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.0.0.weight : Float(1024, 2048, 3, 3, strides=[18432, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.0.0.bias : Float(1024, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.1.0.weight : Float(512, 2048, 3, 3, strides=[18432, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.1.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.2.0.weight : Float(256, 1024, 3, 3, strides=[9216, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.2.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.3.0.weight : Float(128, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.3.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.4.0.weight : Float(64, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.4.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.5.0.weight : Float(32, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.convs.5.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.last_conv.weight : Float(3, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %edge_decoder.last_conv.bias : Float(3, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.0.0.weight : Float(1024, 2048, 3, 3, strides=[18432, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.0.0.bias : Float(1024, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.1.0.weight : Float(512, 3072, 3, 3, strides=[27648, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.1.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.2.0.weight : Float(256, 1536, 3, 3, strides=[13824, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.2.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.3.0.weight : Float(128, 768, 3, 3, strides=[6912, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.3.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.4.0.weight : Float(64, 384, 3, 3, strides=[3456, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.4.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.5.0.weight : Float(32, 192, 3, 3, strides=[1728, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.convs.5.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.last_conv.weight : Float(8, 96, 3, 3, strides=[864, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %corner_decoder.last_conv.bias : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.0.weight : Float(1024, 32768, strides=[32768, 1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.0.bias : Float(1024, strides=[1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.2.weight : Float(256, 1024, strides=[1024, 1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.4.weight : Float(64, 256, strides=[256, 1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.4.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.6.weight : Float(11, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %type_decoder.fcs.6.bias : Float(11, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/encoder/convs.0/convs.0.0/convs.0.0.0/Conv_output_0 : Float(*, 32, 512, 512, strides=[8388608, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.0/convs.0.0/convs.0.0.0/Conv\"](%input, %encoder.convs.0.0.0.weight, %encoder.convs.0.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.container.Sequential::convs.0.0/torch.nn.modules.conv.Conv2d::convs.0.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.0/convs.0.0/convs.0.0.1/Relu_output_0 : Float(*, 32, 512, 512, strides=[8388608, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.0/convs.0.0/convs.0.0.1/Relu\"](%/encoder/convs.0/convs.0.0/convs.0.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.container.Sequential::convs.0.0/torch.nn.modules.activation.ReLU::convs.0.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.0/convs.0.1/MaxPool_output_0 : Float(*, 32, 256, 256, strides=[2097152, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.0/convs.0.1/MaxPool\"](%/encoder/convs.0/convs.0.0/convs.0.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.pooling.MaxPool2d::convs.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.1/convs.1.0/convs.1.0.0/Conv_output_0 : Float(*, 64, 256, 256, strides=[4194304, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.1/convs.1.0/convs.1.0.0/Conv\"](%/encoder/convs.0/convs.0.1/MaxPool_output_0, %encoder.convs.1.0.0.weight, %encoder.convs.1.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.container.Sequential::convs.1.0/torch.nn.modules.conv.Conv2d::convs.1.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.1/convs.1.0/convs.1.0.1/Relu_output_0 : Float(*, 64, 256, 256, strides=[4194304, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.1/convs.1.0/convs.1.0.1/Relu\"](%/encoder/convs.1/convs.1.0/convs.1.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.container.Sequential::convs.1.0/torch.nn.modules.activation.ReLU::convs.1.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.1/convs.1.1/MaxPool_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.1/convs.1.1/MaxPool\"](%/encoder/convs.1/convs.1.0/convs.1.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.pooling.MaxPool2d::convs.1.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.2/convs.2.0/convs.2.0.0/Conv_output_0 : Float(*, 128, 128, 128, strides=[2097152, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.2/convs.2.0/convs.2.0.0/Conv\"](%/encoder/convs.1/convs.1.1/MaxPool_output_0, %encoder.convs.2.0.0.weight, %encoder.convs.2.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.container.Sequential::convs.2.0/torch.nn.modules.conv.Conv2d::convs.2.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.2/convs.2.0/convs.2.0.1/Relu_output_0 : Float(*, 128, 128, 128, strides=[2097152, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.2/convs.2.0/convs.2.0.1/Relu\"](%/encoder/convs.2/convs.2.0/convs.2.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.container.Sequential::convs.2.0/torch.nn.modules.activation.ReLU::convs.2.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.2/convs.2.1/MaxPool_output_0 : Float(*, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.2/convs.2.1/MaxPool\"](%/encoder/convs.2/convs.2.0/convs.2.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.pooling.MaxPool2d::convs.2.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.3/convs.3.0/convs.3.0.0/Conv_output_0 : Float(*, 256, 64, 64, strides=[1048576, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.3/convs.3.0/convs.3.0.0/Conv\"](%/encoder/convs.2/convs.2.1/MaxPool_output_0, %encoder.convs.3.0.0.weight, %encoder.convs.3.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.container.Sequential::convs.3.0/torch.nn.modules.conv.Conv2d::convs.3.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.3/convs.3.0/convs.3.0.1/Relu_output_0 : Float(*, 256, 64, 64, strides=[1048576, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.3/convs.3.0/convs.3.0.1/Relu\"](%/encoder/convs.3/convs.3.0/convs.3.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.container.Sequential::convs.3.0/torch.nn.modules.activation.ReLU::convs.3.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.3/convs.3.1/MaxPool_output_0 : Float(*, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.3/convs.3.1/MaxPool\"](%/encoder/convs.3/convs.3.0/convs.3.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.pooling.MaxPool2d::convs.3.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.4/convs.4.0/convs.4.0.0/Conv_output_0 : Float(*, 512, 32, 32, strides=[524288, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.4/convs.4.0/convs.4.0.0/Conv\"](%/encoder/convs.3/convs.3.1/MaxPool_output_0, %encoder.convs.4.0.0.weight, %encoder.convs.4.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.container.Sequential::convs.4.0/torch.nn.modules.conv.Conv2d::convs.4.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.4/convs.4.0/convs.4.0.1/Relu_output_0 : Float(*, 512, 32, 32, strides=[524288, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.4/convs.4.0/convs.4.0.1/Relu\"](%/encoder/convs.4/convs.4.0/convs.4.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.container.Sequential::convs.4.0/torch.nn.modules.activation.ReLU::convs.4.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.4/convs.4.1/MaxPool_output_0 : Float(*, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.4/convs.4.1/MaxPool\"](%/encoder/convs.4/convs.4.0/convs.4.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.pooling.MaxPool2d::convs.4.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.5/convs.5.0/convs.5.0.0/Conv_output_0 : Float(*, 1024, 16, 16, strides=[262144, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.5/convs.5.0/convs.5.0.0/Conv\"](%/encoder/convs.4/convs.4.1/MaxPool_output_0, %encoder.convs.5.0.0.weight, %encoder.convs.5.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.container.Sequential::convs.5.0/torch.nn.modules.conv.Conv2d::convs.5.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.5/convs.5.0/convs.5.0.1/Relu_output_0 : Float(*, 1024, 16, 16, strides=[262144, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.5/convs.5.0/convs.5.0.1/Relu\"](%/encoder/convs.5/convs.5.0/convs.5.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.container.Sequential::convs.5.0/torch.nn.modules.activation.ReLU::convs.5.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.5/convs.5.1/MaxPool_output_0 : Float(*, 1024, 8, 8, strides=[65536, 64, 8, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.5/convs.5.1/MaxPool\"](%/encoder/convs.5/convs.5.0/convs.5.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.pooling.MaxPool2d::convs.5.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/encoder/convs.6/convs.6.0/convs.6.0.0/Conv_output_0 : Float(*, 2048, 8, 8, strides=[131072, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/encoder/convs.6/convs.6.0/convs.6.0.0/Conv\"](%/encoder/convs.5/convs.5.1/MaxPool_output_0, %encoder.convs.6.0.0.weight, %encoder.convs.6.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.6/torch.nn.modules.container.Sequential::convs.6.0/torch.nn.modules.conv.Conv2d::convs.6.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/encoder/convs.6/convs.6.0/convs.6.0.1/Relu_output_0 : Float(*, 2048, 8, 8, strides=[131072, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/convs.6/convs.6.0/convs.6.0.1/Relu\"](%/encoder/convs.6/convs.6.0/convs.6.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.6/torch.nn.modules.container.Sequential::convs.6.0/torch.nn.modules.activation.ReLU::convs.6.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/encoder/convs.6/convs.6.1/MaxPool_output_0 : Float(*, 2048, 4, 4, strides=[32768, 16, 4, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/encoder/convs.6/convs.6.1/MaxPool\"](%/encoder/convs.6/convs.6.0/convs.6.0.1/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Encoder::encoder/torch.nn.modules.container.Sequential::convs.6/torch.nn.modules.pooling.MaxPool2d::convs.6.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:782:0\n",
      "  %/edge_decoder/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_75 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_output_0 : Float(*, 2048, 8, 8, strides=[131072, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize\"](%/encoder/convs.6/convs.6.1/MaxPool_output_0, %onnx::Resize_75, %/edge_decoder/Constant_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.0/convs.0.0/Conv_output_0 : Float(*, 1024, 8, 8, strides=[65536, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.0/convs.0.0/Conv\"](%/edge_decoder/Resize_output_0, %edge_decoder.convs.0.0.weight, %edge_decoder.convs.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.conv.Conv2d::convs.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.0/convs.0.1/Relu_output_0 : Float(*, 1024, 8, 8, strides=[65536, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.0/convs.0.1/Relu\"](%/edge_decoder/convs.0/convs.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.activation.ReLU::convs.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_output_0 : Float(*, 2048, 8, 8, strides=[131072, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat\"](%/edge_decoder/convs.0/convs.0.1/Relu_output_0, %/encoder/convs.5/convs.5.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_1_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_1\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_83 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_1_output_0 : Float(*, 2048, 16, 16, strides=[524288, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_1\"](%/edge_decoder/Concat_output_0, %onnx::Resize_83, %/edge_decoder/Constant_1_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.1/convs.1.0/Conv_output_0 : Float(*, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.1/convs.1.0/Conv\"](%/edge_decoder/Resize_1_output_0, %edge_decoder.convs.1.0.weight, %edge_decoder.convs.1.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.conv.Conv2d::convs.1.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.1/convs.1.1/Relu_output_0 : Float(*, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.1/convs.1.1/Relu\"](%/edge_decoder/convs.1/convs.1.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.activation.ReLU::convs.1.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_1_output_0 : Float(*, 1024, 16, 16, strides=[262144, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat_1\"](%/edge_decoder/convs.1/convs.1.1/Relu_output_0, %/encoder/convs.4/convs.4.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_2_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_2\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_91 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_2_output_0 : Float(*, 1024, 32, 32, strides=[1048576, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_2\"](%/edge_decoder/Concat_1_output_0, %onnx::Resize_91, %/edge_decoder/Constant_2_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.2/convs.2.0/Conv_output_0 : Float(*, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.2/convs.2.0/Conv\"](%/edge_decoder/Resize_2_output_0, %edge_decoder.convs.2.0.weight, %edge_decoder.convs.2.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.conv.Conv2d::convs.2.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.2/convs.2.1/Relu_output_0 : Float(*, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.2/convs.2.1/Relu\"](%/edge_decoder/convs.2/convs.2.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.activation.ReLU::convs.2.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_2_output_0 : Float(*, 512, 32, 32, strides=[524288, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat_2\"](%/edge_decoder/convs.2/convs.2.1/Relu_output_0, %/encoder/convs.3/convs.3.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_3_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_3\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_99 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_3_output_0 : Float(*, 512, 64, 64, strides=[2097152, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_3\"](%/edge_decoder/Concat_2_output_0, %onnx::Resize_99, %/edge_decoder/Constant_3_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.3/convs.3.0/Conv_output_0 : Float(*, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.3/convs.3.0/Conv\"](%/edge_decoder/Resize_3_output_0, %edge_decoder.convs.3.0.weight, %edge_decoder.convs.3.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.conv.Conv2d::convs.3.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.3/convs.3.1/Relu_output_0 : Float(*, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.3/convs.3.1/Relu\"](%/edge_decoder/convs.3/convs.3.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.activation.ReLU::convs.3.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_3_output_0 : Float(*, 256, 64, 64, strides=[1048576, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat_3\"](%/edge_decoder/convs.3/convs.3.1/Relu_output_0, %/encoder/convs.2/convs.2.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_4_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_4\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_107 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_4_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_4\"](%/edge_decoder/Concat_3_output_0, %onnx::Resize_107, %/edge_decoder/Constant_4_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.4/convs.4.0/Conv_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.4/convs.4.0/Conv\"](%/edge_decoder/Resize_4_output_0, %edge_decoder.convs.4.0.weight, %edge_decoder.convs.4.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.conv.Conv2d::convs.4.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.4/convs.4.1/Relu_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.4/convs.4.1/Relu\"](%/edge_decoder/convs.4/convs.4.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.activation.ReLU::convs.4.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_4_output_0 : Float(*, 128, 128, 128, strides=[2097152, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat_4\"](%/edge_decoder/convs.4/convs.4.1/Relu_output_0, %/encoder/convs.1/convs.1.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_5_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_5\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_115 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_5_output_0 : Float(*, 128, 256, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_5\"](%/edge_decoder/Concat_4_output_0, %onnx::Resize_115, %/edge_decoder/Constant_5_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/convs.5/convs.5.0/Conv_output_0 : Float(*, 32, 256, 256, strides=[2097152, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/convs.5/convs.5.0/Conv\"](%/edge_decoder/Resize_5_output_0, %edge_decoder.convs.5.0.weight, %edge_decoder.convs.5.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.conv.Conv2d::convs.5.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/edge_decoder/convs.5/convs.5.1/Relu_output_0 : Float(*, 32, 256, 256, strides=[2097152, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/edge_decoder/convs.5/convs.5.1/Relu\"](%/edge_decoder/convs.5/convs.5.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.activation.ReLU::convs.5.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/edge_decoder/Concat_5_output_0 : Float(*, 64, 256, 256, strides=[4194304, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/edge_decoder/Concat_5\"](%/edge_decoder/convs.5/convs.5.1/Relu_output_0, %/encoder/convs.0/convs.0.1/MaxPool_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/edge_decoder/Constant_6_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/edge_decoder/Constant_6\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_123 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/Resize_6_output_0 : Float(*, 64, 512, 512, strides=[16777216, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/edge_decoder/Resize_6\"](%/edge_decoder/Concat_5_output_0, %onnx::Resize_123, %/edge_decoder/Constant_6_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/edge_decoder/last_conv/Conv_output_0 : Float(*, 3, 512, 512, strides=[786432, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/edge_decoder/last_conv/Conv\"](%/edge_decoder/Resize_6_output_0, %edge_decoder.last_conv.weight, %edge_decoder.last_conv.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::edge_decoder/torch.nn.modules.conv.Conv2d::last_conv # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.0/convs.0.0/Conv_output_0 : Float(*, 1024, 8, 8, strides=[65536, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.0/convs.0.0/Conv\"](%/edge_decoder/Resize_output_0, %corner_decoder.convs.0.0.weight, %corner_decoder.convs.0.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.conv.Conv2d::convs.0.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.0/convs.0.1/Relu_output_0 : Float(*, 1024, 8, 8, strides=[65536, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.0/convs.0.1/Relu\"](%/corner_decoder/convs.0/convs.0.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.0/torch.nn.modules.activation.ReLU::convs.0.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_output_0 : Float(*, 3072, 8, 8, strides=[196608, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat\"](%/corner_decoder/convs.0/convs.0.1/Relu_output_0, %/edge_decoder/Concat_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_132 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_output_0 : Float(*, 3072, 16, 16, strides=[786432, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize\"](%/corner_decoder/Concat_output_0, %onnx::Resize_132, %/corner_decoder/Constant_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/convs.1/convs.1.0/Conv_output_0 : Float(*, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.1/convs.1.0/Conv\"](%/corner_decoder/Resize_output_0, %corner_decoder.convs.1.0.weight, %corner_decoder.convs.1.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.conv.Conv2d::convs.1.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.1/convs.1.1/Relu_output_0 : Float(*, 512, 16, 16, strides=[131072, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.1/convs.1.1/Relu\"](%/corner_decoder/convs.1/convs.1.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.1/torch.nn.modules.activation.ReLU::convs.1.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_1_output_0 : Float(*, 1536, 16, 16, strides=[393216, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat_1\"](%/corner_decoder/convs.1/convs.1.1/Relu_output_0, %/edge_decoder/Concat_1_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_1_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant_1\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_140 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_1_output_0 : Float(*, 1536, 32, 32, strides=[1572864, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize_1\"](%/corner_decoder/Concat_1_output_0, %onnx::Resize_140, %/corner_decoder/Constant_1_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/convs.2/convs.2.0/Conv_output_0 : Float(*, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.2/convs.2.0/Conv\"](%/corner_decoder/Resize_1_output_0, %corner_decoder.convs.2.0.weight, %corner_decoder.convs.2.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.conv.Conv2d::convs.2.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.2/convs.2.1/Relu_output_0 : Float(*, 256, 32, 32, strides=[262144, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.2/convs.2.1/Relu\"](%/corner_decoder/convs.2/convs.2.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.2/torch.nn.modules.activation.ReLU::convs.2.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_2_output_0 : Float(*, 768, 32, 32, strides=[786432, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat_2\"](%/corner_decoder/convs.2/convs.2.1/Relu_output_0, %/edge_decoder/Concat_2_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_2_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant_2\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_148 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_2_output_0 : Float(*, 768, 64, 64, strides=[3145728, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize_2\"](%/corner_decoder/Concat_2_output_0, %onnx::Resize_148, %/corner_decoder/Constant_2_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/convs.3/convs.3.0/Conv_output_0 : Float(*, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.3/convs.3.0/Conv\"](%/corner_decoder/Resize_2_output_0, %corner_decoder.convs.3.0.weight, %corner_decoder.convs.3.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.conv.Conv2d::convs.3.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.3/convs.3.1/Relu_output_0 : Float(*, 128, 64, 64, strides=[524288, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.3/convs.3.1/Relu\"](%/corner_decoder/convs.3/convs.3.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.3/torch.nn.modules.activation.ReLU::convs.3.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_3_output_0 : Float(*, 384, 64, 64, strides=[1572864, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat_3\"](%/corner_decoder/convs.3/convs.3.1/Relu_output_0, %/edge_decoder/Concat_3_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_3_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant_3\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_156 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_3_output_0 : Float(*, 384, 128, 128, strides=[6291456, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize_3\"](%/corner_decoder/Concat_3_output_0, %onnx::Resize_156, %/corner_decoder/Constant_3_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/convs.4/convs.4.0/Conv_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.4/convs.4.0/Conv\"](%/corner_decoder/Resize_3_output_0, %corner_decoder.convs.4.0.weight, %corner_decoder.convs.4.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.conv.Conv2d::convs.4.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.4/convs.4.1/Relu_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.4/convs.4.1/Relu\"](%/corner_decoder/convs.4/convs.4.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.4/torch.nn.modules.activation.ReLU::convs.4.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_4_output_0 : Float(*, 192, 128, 128, strides=[3145728, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat_4\"](%/corner_decoder/convs.4/convs.4.1/Relu_output_0, %/edge_decoder/Concat_4_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_4_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant_4\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_164 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_4_output_0 : Float(*, 192, 256, 256, strides=[12582912, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize_4\"](%/corner_decoder/Concat_4_output_0, %onnx::Resize_164, %/corner_decoder/Constant_4_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/convs.5/convs.5.0/Conv_output_0 : Float(*, 32, 256, 256, strides=[2097152, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/convs.5/convs.5.0/Conv\"](%/corner_decoder/Resize_4_output_0, %corner_decoder.convs.5.0.weight, %corner_decoder.convs.5.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.conv.Conv2d::convs.5.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/corner_decoder/convs.5/convs.5.1/Relu_output_0 : Float(*, 32, 256, 256, strides=[2097152, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/corner_decoder/convs.5/convs.5.1/Relu\"](%/corner_decoder/convs.5/convs.5.0/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.container.Sequential::convs.5/torch.nn.modules.activation.ReLU::convs.5.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/corner_decoder/Concat_5_output_0 : Float(*, 96, 256, 256, strides=[6291456, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/corner_decoder/Concat_5\"](%/corner_decoder/convs.5/convs.5.1/Relu_output_0, %/edge_decoder/Concat_5_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:58:0\n",
      "  %/corner_decoder/Constant_5_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/corner_decoder/Constant_5\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %onnx::Resize_172 : Tensor? = prim::Constant(), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/Resize_5_output_0 : Float(*, 96, 512, 512, strides=[25165824, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/corner_decoder/Resize_5\"](%/corner_decoder/Concat_5_output_0, %onnx::Resize_172, %/corner_decoder/Constant_5_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:3931:0\n",
      "  %/corner_decoder/last_conv/Conv_output_0 : Float(*, 8, 512, 512, strides=[2097152, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/corner_decoder/last_conv/Conv\"](%/corner_decoder/Resize_5_output_0, %corner_decoder.last_conv.weight, %corner_decoder.last_conv.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.Decoder::corner_decoder/torch.nn.modules.conv.Conv2d::last_conv # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/type_decoder/Constant_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=     1  32768 [ CPULongType{2} ], onnx_name=\"/type_decoder/Constant\"](), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:77:0\n",
      "  %/type_decoder/Reshape_output_0 : Float(1, 32768, strides=[32768, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/type_decoder/Reshape\"](%/encoder/convs.6/convs.6.1/MaxPool_output_0, %/type_decoder/Constant_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder # /home/richard/Development/pytorch-layoutnet-perspective/model_persp.py:77:0\n",
      "  %/type_decoder/fcs.0/Gemm_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/type_decoder/fcs.0/Gemm\"](%/type_decoder/Reshape_output_0, %type_decoder.fcs.0.weight, %type_decoder.fcs.0.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.linear.Linear::fcs.0 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/type_decoder/fcs.1/Relu_output_0 : Float(1, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/type_decoder/fcs.1/Relu\"](%/type_decoder/fcs.0/Gemm_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.activation.ReLU::fcs.1 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/type_decoder/fcs.2/Gemm_output_0 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/type_decoder/fcs.2/Gemm\"](%/type_decoder/fcs.1/Relu_output_0, %type_decoder.fcs.2.weight, %type_decoder.fcs.2.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.linear.Linear::fcs.2 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/type_decoder/fcs.3/Relu_output_0 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/type_decoder/fcs.3/Relu\"](%/type_decoder/fcs.2/Gemm_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.activation.ReLU::fcs.3 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/type_decoder/fcs.4/Gemm_output_0 : Float(1, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/type_decoder/fcs.4/Gemm\"](%/type_decoder/fcs.3/Relu_output_0, %type_decoder.fcs.4.weight, %type_decoder.fcs.4.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.linear.Linear::fcs.4 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/type_decoder/fcs.5/Relu_output_0 : Float(1, 64, strides=[64, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/type_decoder/fcs.5/Relu\"](%/type_decoder/fcs.4/Gemm_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.activation.ReLU::fcs.5 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/type_decoder/fcs.6/Gemm_output_0 : Float(1, 11, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/type_decoder/fcs.6/Gemm\"](%/type_decoder/fcs.5/Relu_output_0, %type_decoder.fcs.6.weight, %type_decoder.fcs.6.bias), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.linear.Linear::fcs.6 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/type_decoder/fcs.7/Relu_output_0 : Float(1, 11, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/type_decoder/fcs.7/Relu\"](%/type_decoder/fcs.6/Gemm_output_0), scope: model_wrapper.CombinedLayoutNetPersp::/model_persp.TypeDecoder::type_decoder/torch.nn.modules.activation.ReLU::fcs.7 # /home/richard/miniconda3/envs/layoutnet-perspective/lib/python3.11/site-packages/torch/nn/functional.py:1455:0\n",
      "  %edge : Float(*, 3, 512, 512, strides=[786432, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid\"](%/edge_decoder/last_conv/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp:: # /home/richard/Development/pytorch-layoutnet-perspective/model_wrapper.py:32:0\n",
      "  %corner : Float(*, 8, 512, 512, strides=[2097152, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_1\"](%/corner_decoder/last_conv/Conv_output_0), scope: model_wrapper.CombinedLayoutNetPersp:: # /home/richard/Development/pytorch-layoutnet-perspective/model_wrapper.py:33:0\n",
      "  %type : Float(1, 11, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=1, onnx_name=\"/Softmax\"](%/type_decoder/fcs.7/Relu_output_0), scope: model_wrapper.CombinedLayoutNetPersp:: # /home/richard/Development/pytorch-layoutnet-perspective/model_wrapper.py:34:0\n",
      "  return (%edge, %corner, %type)\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_model.to_onnx(\n",
    "    './ckpt/combined_model.onnx',\n",
    "    verbose=True, \n",
    "    export_params=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['edge', 'corner', 'type'],\n",
    "    dynamic_axes={\n",
    "        'input' : {0 : 'batch_size'},\n",
    "        'edge' : {0 : 'batch_size'},\n",
    "        'corner' : {0 : 'batch_size'},\n",
    "        'type' : {0 : 'batch_size'},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.274075Z",
     "start_time": "2023-07-23T10:20:39.264157Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: now create wrapper model around combined model that will perform basic result preprocessing and postprocessing (flip, etc)\n",
    "#   (and preprocessing, if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoreML Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = torch.rand_like(combined_model.example_input_array)\n",
    "\n",
    "combined_model = combined_model.eval()\n",
    "\n",
    "traced_model = combined_model.to_torchscript(method='trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ct.convert(\n",
    "#     traced_model,\n",
    "#     convert_to=\"mlprogram\",\n",
    "#     inputs=[ct.TensorType(shape=example.shape)]\n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./ckpt/combined_model.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512, 512]),\n",
       " torch.Size([1, 8, 512, 512]),\n",
       " torch.Size([1, 11]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    edge_tensor, corner_tensor, type_tensor = traced_model(combined_model.example_input_array)\n",
    "\n",
    "edge_tensor.shape, corner_tensor.shape, type_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.274421Z",
     "start_time": "2023-07-23T10:20:39.269244Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.486443Z",
     "start_time": "2023-07-23T10:20:39.271755Z"
    }
   },
   "outputs": [],
   "source": [
    "# image = Image.open('./images/room4.jpg')\n",
    "# image = Image.open('./images/room0.jpg')\n",
    "# image = Image.open('./images/room9.jpg')\n",
    "# image = Image.open('./images/room5.jpg')\n",
    "# image = Image.open('./images/room6.jpg')\n",
    "# image = Image.open('./images/room_0_2.jpeg')\n",
    "# image = Image.open('./images/room_0_3.jpeg')\n",
    "image = Image.open('./images/room5_2.jpeg')\n",
    "\n",
    "input_image = np.array(image.resize((512, 512)), np.float32) / 255\n",
    "\n",
    "plt.imshow(input_image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.494434Z",
     "start_time": "2023-07-23T10:20:39.485790Z"
    }
   },
   "outputs": [],
   "source": [
    "x_img = input_image.transpose([2, 0, 1]) # HWC -> CHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:39.502080Z",
     "start_time": "2023-07-23T10:20:39.491421Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x_img)\n",
    "# Add batch dimension to make it NCHW\n",
    "x = x.unsqueeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:40.513089Z",
     "start_time": "2023-07-23T10:20:39.508419Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    [edg_de_list, cor_de_list, type_tensor] = combined_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edg_de_list[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:40.518524Z",
     "start_time": "2023-07-23T10:20:40.513642Z"
    }
   },
   "outputs": [],
   "source": [
    "edg_tensor = torch.sigmoid(edg_de_list[-1])\n",
    "cor_tensor = torch.sigmoid(cor_de_list[-1])\n",
    "\n",
    "print(f'edg_tensor shape: {edg_tensor.shape}\\ncor_tensor shape: {cor_tensor.shape}')\n",
    "\n",
    "# # Recover the effect from augmentation\n",
    "# edg_img = augment_undo(edg_tensor.cpu().numpy(), aug_type)\n",
    "# cor_img = augment_undo(cor_tensor.cpu().numpy(), aug_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:40.526998Z",
     "start_time": "2023-07-23T10:20:40.519348Z"
    }
   },
   "outputs": [],
   "source": [
    "type_tensor = type_tensor.softmax(1)\n",
    "print(f'Type tensor: {type_tensor}\\nRoom type: {type_tensor.argmax()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:40.628728Z",
     "start_time": "2023-07-23T10:20:40.524698Z"
    }
   },
   "outputs": [],
   "source": [
    "edg_tensor_image = edg_tensor.squeeze().permute((1, 2, 0)) # NCHW -> HWC\n",
    "print(edg_tensor_image.shape)\n",
    "\n",
    "plt.imshow(edg_tensor_image)\n",
    "plt.axis('off')\n",
    "plt.title('Edge map');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:41.093192Z",
     "start_time": "2023-07-23T10:20:40.628161Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner_tensor = cor_tensor.squeeze().permute((1, 2, 0))\n",
    "for channel_idx in range(0, corner_tensor.shape[-1]):\n",
    "    plt.figure()\n",
    "    plt.imshow(corner_tensor[:, :, channel_idx])\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Channel {channel_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:25:45.780043Z",
     "start_time": "2023-07-23T10:25:45.627197Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: blend edges, corners on image\n",
    "image_overlay = np.array(image.copy().resize((512, 512)))\n",
    "\n",
    "edge_mask = (edg_tensor_image.numpy() * 255).astype(np.uint8)\n",
    "image_overlay = cv2.addWeighted(\n",
    "    image_overlay, \n",
    "    1.0,\n",
    "    edge_mask, \n",
    "    1.0,\n",
    "    0\n",
    ")\n",
    "\n",
    "for channel_idx in range(0, corner_tensor.shape[-1]):\n",
    "    corner_map = (corner_tensor[:, :, channel_idx].numpy() * 255).astype(np.uint8)\n",
    "    corner_image = np.zeros_like(image_overlay)\n",
    "    corner_image[:, :, 0] = corner_map\n",
    "    corner_image[:, :, 0] = corner_map\n",
    "    corner_image[:, :, 2] = corner_map\n",
    "    image_overlay = cv2.addWeighted(\n",
    "        image_overlay, \n",
    "        1.0,\n",
    "        corner_image, \n",
    "        1.0,\n",
    "        0\n",
    "    )\n",
    "\n",
    "\n",
    "plt.imshow(image_overlay)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:23:51.335949Z",
     "start_time": "2023-07-23T10:23:51.295613Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner_map[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:20:41.348681Z",
     "start_time": "2023-07-23T10:20:41.340789Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_overlay.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:23:14.249984Z",
     "start_time": "2023-07-23T10:23:14.201319Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_mask[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T10:31:10.395044Z",
     "start_time": "2023-07-23T10:31:10.340221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner_tensor.mean(0)[..., 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layoutnetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
